{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "> When more than one feature is used in a linear regression model.\n",
    ">> The hypothesis in this case is that the prediction function will be of the form: $p(x) = a0 + a1x1 + a2x2 + a3x3 + ...$ ; where x1, x2, x3 ... are the features of the dataset and the parameters a0, a1, a2, ... are the constants we want to discover in order to form the prediction function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "> Assuming x0 = 1, x1, x2, x3, ... compose a vector called x; and a0, a1, a2, ... a vector called a, the prediction function can be writen as $p(x) = aTx$, where aT is the transpose of the vector a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "> the algorithm used to update the parameters in this case is analogous to the one used in linear regression and is given by: $aj := aj - l/m(sum(i->m)(p(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
